# ğŸ’¼ Salary Prediction System

An intelligent **Machine Learning web application** that predicts employee salaries based on inputs like age, department, experience, and education.  
It also provides **AI-generated insights** using **Google Gemini** (or any other LLM API key configured by the user).

---

## ğŸš€ Live Demo
ğŸ‘‰ [https://salary-prediction-gi9d.onrender.com/]()

---

## ğŸ§  Project Overview

The project allows both **manual** and **bulk (CSV)** salary predictions, supported by:

- ğŸ¤– **AI-powered salary insights** using Gemini API  
- ğŸ¨ **Beautiful Bootstrap UI**  
- â³ **Real-time â€œPredictingâ€¦ Please waitâ€ status**  
- â˜ï¸ **Deployed on Render for public access**

---

## ğŸ§© Features

| Feature | Description |
|----------|--------------|
| ğŸ’¡ **AI Insights** | Powered by Google Gemini |
| ğŸ“„ **Bulk Upload** | Upload CSV for multiple predictions |
| ğŸ§® **ML Model** | Trained using Scikit-learn |
| ğŸŒ **Responsive UI** | Built with Flask + Bootstrap |
| â˜ï¸ **Cloud Deployment** | Hosted on Render |

---

## ğŸ› ï¸ Tech Stack

| Category | Tools / Libraries |
|-----------|------------------|
| **Frontend** | HTML5, CSS3, Bootstrap 5 |
| **Backend** | Python, Flask |
| **Machine Learning** | Scikit-learn, Pandas, NumPy |
| **AI Integration** | Google Gemini API (`google-generativeai`) |
| **Deployment** | Render |
| **Version Control** | Git, GitHub |

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/nithish1921/salary-prediction-system.git
cd salary-prediction-system
```

### 2ï¸âƒ£ Create Virtual Environment
```bash
python -m venv venv
venv\Scripts\activate      # On Windows
# or
source venv/bin/activate   # On macOS/Linux
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ”‘ Setting Up the API Key (LLM AI Insight)

The project uses **Google Gemini** for generating AI insights about predicted salaries.

### â¤ Option 1: Using `.env` file (Recommended)
Create a file named `.env` in your project folder and add:
```
GEMINI_API_KEY=your_actual_api_key_here
```

In your `app.py`, ensure you have the following:
```python
from dotenv import load_dotenv
import os, google.generativeai as genai

load_dotenv()  # Load environment variables

def llm_call(prediction, params):
    try:
        genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
        model = genai.GenerativeModel("gemini-2.5-flash")
        # ... your model logic here ...
    except Exception as e:
        print("LLM Error:", e)
```

---

### â¤ Option 2: Using a Different API (e.g., OpenAI, Claude)
If youâ€™re using another AI provider, replace your `.env` content with:
```
OPENAI_API_KEY=your_openai_key_here
```

Then modify your configuration in `app.py`:
```python
# Replace Gemini config with your preferred API
genai.configure(api_key=os.getenv("OPENAI_API_KEY"))
model = genai.GenerativeModel("your-model-name-here")
```

âš ï¸ **Important:**  
Make sure you update **both**:
1. The `.env` variable name  
2. The corresponding `os.getenv()` call in your code

---

## â–¶ï¸ Running the Application

### For local testing:
```python
if __name__ == '__main__':
    app.run(debug=True)
```

### For production (Render deployment):
Uncomment the `serve()` line:
```python
if __name__ == '__main__':
    # serve(app, host='0.0.0.0', port=8080)  # For production (Render)
    app.run(debug=True)  # For local testing only
```

---

## ğŸ“š Future Enhancements

- ğŸ” Add user authentication  
- ğŸ“Š Data visualization for salary trends  
- ğŸ§  Support multiple AI models (Gemini / OpenAI / Claude)  
- ğŸ’¾ Database storage for previous predictions  

---

## ğŸ§‘â€ğŸ’» Author

**Your Name**  
ğŸ“§ your.email@example.com  
ğŸŒ [LinkedIn](https://linkedin.com/in/yourprofile) | [GitHub](https://github.com/yourusername)

---

â­ **If you like this project, donâ€™t forget to give it a star on GitHub!**
